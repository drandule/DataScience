{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61fcc3c-71e3-4aad-94f7-42ad6f2d7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–∏–º–ø–æ—Ä—Ç\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81c45b7-c917-4849-ae62-98c12f3f1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "##–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "def load_bbc_data(data_path='bbc'):\n",
    "    classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "    texts, labels = [], []\n",
    "\n",
    "    for label in classes:\n",
    "        class_dir = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_dir):\n",
    "            with open(os.path.join(class_dir, file), 'r', encoding='latin-1') as f:\n",
    "                texts.append(f.read())\n",
    "                labels.append(label)\n",
    "\n",
    "    return pd.DataFrame({'text': texts, 'label': labels})\n",
    "\n",
    "def load_additional_data(data_path='bbc_additional'):\n",
    "    classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "    texts, labels, filenames = [], [], []\n",
    "\n",
    "    for label in classes:\n",
    "        class_dir = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_dir):\n",
    "            file_path = os.path.join(class_dir, file)\n",
    "            with open(file_path, 'r', encoding='latin-1') as f:\n",
    "                    texts.append(f.read())\n",
    "                    labels.append(label)\n",
    "                    filenames.append(file)\n",
    "    return pd.DataFrame({'filename': filenames, 'text': texts, 'true_label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ba9abc-11d5-496f-b280-f3fdef6287fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicNewsClassifier:\n",
    "    def __init__(self):\n",
    "        self.pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=10000,\n",
    "                stop_words='english',\n",
    "                ngram_range=(1,2))),\n",
    "            ('clf', LogisticRegression(\n",
    "                multi_class='multinomial',\n",
    "                solver='lbfgs',\n",
    "                max_iter=10000,\n",
    "                random_state=42))\n",
    "        ])\n",
    "\n",
    "    def train(self, data, test_size=0.2):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['text'], data['label'],\n",
    "            test_size=test_size,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # –û—Ü–µ–Ω–∫–∞\n",
    "        preds = self.pipeline.predict(X_test)\n",
    "        return f\"Accuracy: {accuracy_score(y_test, preds):.3f}\",classification_report(y_test, preds)\n",
    "\n",
    "    def predict(self, texts):\n",
    "        probs = self.pipeline.predict_proba(texts)\n",
    "        preds = self.pipeline.classes_[probs.argmax(axis=1)]\n",
    "        return list(zip(preds, probs.max(axis=1)))\n",
    "\n",
    "    def save(self, path='classic_model.joblib'):\n",
    "        joblib.dump(self.pipeline, path)\n",
    "    def load(self, path='classic_model.joblib'):\n",
    "        self.pipeline = joblib.load(path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3088d150-16db-4c02-843b-3f9d6fd4b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—É—á–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\37529\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.97      0.96      0.97       110\n",
      "entertainment       0.99      0.99      0.99        70\n",
      "     politics       0.96      0.96      0.96        82\n",
      "        sport       0.99      1.00      0.99        94\n",
      "         tech       0.97      0.97      0.97        89\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n",
      "\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º bbc_additional...\n",
      "   filename     true_label predicted_label  confidence\n",
      "0     1.txt       business        business    0.476177\n",
      "1     2.txt       business        business    0.679378\n",
      "2     3.txt       business        business    0.510757\n",
      "3     4.txt       business        business    0.604171\n",
      "4     5.txt       business        business    0.430783\n",
      "5     1.txt  entertainment   entertainment    0.548307\n",
      "6     2.txt  entertainment   entertainment    0.366793\n",
      "7     3.txt  entertainment   entertainment    0.729959\n",
      "8     4.txt  entertainment   entertainment    0.575341\n",
      "9     5.txt  entertainment   entertainment    0.831481\n",
      "10    1.txt       politics        politics    0.588167\n",
      "11    2.txt       politics        politics    0.499245\n",
      "12    3.txt       politics        politics    0.584189\n",
      "13    4.txt       politics        politics    0.520341\n",
      "14    5.txt       politics        politics    0.441752\n",
      "15    1.txt          sport           sport    0.825257\n",
      "16    2.txt          sport           sport    0.562450\n",
      "17    3.txt          sport           sport    0.364842\n",
      "18    4.txt          sport           sport    0.684573\n",
      "19    5.txt          sport           sport    0.858344\n",
      "20    1.txt           tech            tech    0.640653\n",
      "21    2.txt           tech            tech    0.363948\n",
      "22    3.txt           tech        business    0.250638\n",
      "23    4.txt           tech        business    0.544233\n",
      "24    5.txt           tech            tech    0.528102\n",
      "\n",
      "Accuracy on additional dataset: 0.920\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'bbc_additional_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_path = 'classic_model.joblib'\n",
    "\n",
    "    print(\"–û–±—É—á–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å...\")\n",
    "    df = load_bbc_data()\n",
    "    classifier = ClassicNewsClassifier()\n",
    "    acc,report=classifier.train(df)\n",
    "    print(acc)\n",
    "    print(report)\n",
    "    classifier.save()\n",
    "    \n",
    "    # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    print(\"\\n–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º bbc_additional...\")\n",
    "    df_additional = load_additional_data()\n",
    "    df_additional['predicted_label'], df_additional['confidence'] = zip(*classifier.predict(df_additional['text']))\n",
    "\n",
    "    \n",
    "    print(df_additional[['filename', 'true_label', 'predicted_label', 'confidence']])\n",
    "\n",
    "    \n",
    "    accuracy = (df_additional['true_label'] == df_additional['predicted_label']).mean()\n",
    "    print(f\"\\nAccuracy on additional dataset: {accuracy:.3f}\")\n",
    "\n",
    "    \n",
    "    df_additional.to_csv('bbc_additional_predictions.csv', index=False)\n",
    "    print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'bbc_additional_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f35dd24b-73c7-47a1-88fc-62eff48129f5",
   "metadata": {},
   "source": [
    "bbc/business/1.txt\thttps://www.bbc.com/news/articles/cx20yw9e8yqo\n",
    "bbc/business/2.txt\thttps://www.bbc.com/news/articles/ckgzjn7m0vvo\n",
    "bbc/business/3.txt\thttps://www.bbc.com/news/articles/c3e4d8epdzdo\n",
    "bbc/business/4.txt\thttps://www.bbc.com/news/articles/cm2y8222ye4o\n",
    "bbc/business/5.txt\thttps://www.bbc.com/news/articles/cx2r3md0j84o\n",
    "\n",
    "bbs/entertainment/1.txt\thttps://www.bbc.com/news/articles/c4gp6ljnq23o\n",
    "bbs/entertainment/2.txt\thttps://www.bbc.com/news/articles/c0mwp3yp972o\n",
    "bbs/entertainment/3.txt\thttps://www.bbc.com/news/articles/c6253d37ylvo\n",
    "bbs/entertainment/4.txt\thttps://www.bbc.com/news/articles/cly41ww6e2do\n",
    "bbs/entertainment/5.txt\thttps://www.bbc.com/news/videos/cg4kvg02w7ko\n",
    "\n",
    "bbs/politics/1.txt\thttps://www.bbc.com/news/articles/c70w17dj258o\n",
    "bbs/politics/2.txt\thttps://www.bbc.com/news/articles/cvg5j74ld9lo\n",
    "bbs/politics/3.txt\thttps://www.bbc.com/news/articles/c4g0pp3mz1wo\n",
    "bbs/politics/4.txt\thttps://www.bbc.com/news/articles/cm2y82rk4kpo\n",
    "bbs/politics/5.txt\thttps://www.bbc.com/news/articles/cly6gz9j3rno\n",
    "\n",
    "\n",
    "bbs/sport/1.txt\thttps://www.bbc.com/sport/cricket/articles/cvgpjr7v5zmo\n",
    "bbs/sport/2.txt\thttps://www.bbc.com/sport/football/articles/cgm14y04g04o\n",
    "bbs/sport/3.txt\thttps://www.bbc.com/sport/horse-racing/articles/c4gdr979k5po\n",
    "bbs/sport/4.txt\thttps://www.bbc.com/sport/formula1/articles/ce8mr3rvyd5o\n",
    "bbs/sport/5.txt\thttps://www.bbc.com/sport/rugby-union/articles/cge1z2y0pg2o\n",
    "\n",
    "bbs/tech/1.txt\thttps://www.bbc.com/news/articles/c5yrjkl7dd6o\n",
    "bbs/tech/2.txt\thttps://www.bbc.com/news/articles/cz61yxv6evjo\n",
    "bbs/tech/3.txt\thttps://www.bbc.com/news/articles/ckgnvyggye1o\n",
    "bbs/tech/4.txt\thttps://www.bbc.com/news/articles/cdjy8x9w9zzo\n",
    "bbs/tech/5.txt\thttps://www.bbc.com/news/articles/czdnv6le71eo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5baf7c8a-2999-43cd-9b28-dd40f7ffed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\37529\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\37529\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\37529\\anaconda3\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\37529\\anaconda3\\lib\\site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\37529\\anaconda3\\lib\\site-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\37529\\anaconda3\\lib\\site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\37529\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\37529\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\37529\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\37529\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\37529\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\37529\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate>=0.26.0\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94302ebf-9af8-4715-bd5c-576421b74c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch; print(torch. cuda. is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9af1788d-5684-4d31-b036-cfff46cdcd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "import torch\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4720d613-38b2-4841-9d5a-6943bfda8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertNewsClassifier:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        \n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "        \n",
    "        self.label2id = {'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n",
    "        self.id2label = {v: k for k, v in self.label2id.items()}\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self, data_path='bbc'):\n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ \n",
    "        df = self._load_bbc_data(data_path)\n",
    "        return Dataset.from_pandas(df).train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "    def _load_bbc_data(self, path):\n",
    "        \n",
    "        classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "        texts, labels = [], []\n",
    "\n",
    "        for cls in classes:\n",
    "            cls_dir = os.path.join(path, cls)\n",
    "            for file in os.listdir(cls_dir):\n",
    "                with open(os.path.join(cls_dir, file), 'r', encoding='latin-1') as f:\n",
    "                    texts.append(f.read())\n",
    "                    labels.append(cls)\n",
    "\n",
    "        return pd.DataFrame({'text': texts, 'label': labels})\n",
    "\n",
    "    def tokenize(self, examples):\n",
    "        \n",
    "        tokenized = self.tokenizer(\n",
    "            examples['text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        tokenized['labels'] = [self.label2id[label] for label in examples['label']]\n",
    "        return tokenized\n",
    "\n",
    "    def train(self, data):\n",
    "        \n",
    "        dataset = data.map(self.tokenize, batched=True)\n",
    "        dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "        # init\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(\n",
    "            'distilbert-base-uncased',\n",
    "            num_labels=5,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id\n",
    "        ).to(self.device)  # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "\n",
    "        # parameters\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            num_train_epochs=10,\n",
    "            per_device_train_batch_size=16,\n",
    "            evaluation_strategy='epoch',\n",
    "            logging_dir='./logs',\n",
    "            learning_rate=2e-5,\n",
    "            save_strategy='no'\n",
    "        )\n",
    "\n",
    "         \n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset['train'],\n",
    "            eval_dataset=dataset['test'],\n",
    "            compute_metrics=lambda p: {\n",
    "                'accuracy': (p.predictions.argmax(-1) == p.label_ids).mean()\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # –æ–±—É—á–µ–Ω–∏–µ\n",
    "        trainer.train()\n",
    "\n",
    "        # —ç–≤–∞–ª\n",
    "        self.model.eval()\n",
    "        print(f\"Validation Accuracy: {trainer.evaluate()['eval_accuracy']:.3f}\")\n",
    "\n",
    "    def predict(self, texts):\n",
    "         \n",
    "        self.model.to(self.device)\n",
    "        inputs = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "        return [\n",
    "            (self.id2label[p.item()], probs[i][p].item())  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã —Å–∫–æ–±–∫–∏\n",
    "            for i, p in enumerate(preds)\n",
    "        ]\n",
    "\n",
    "    def save(self, path='bert_model'):\n",
    "        # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "        self.model.save_pretrained(path)\n",
    "        self.tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "037c7545-8c6f-4686-8fcc-b03d13cdf671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d93bc3a98c948dcb70e594d9dc884e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febc41f07b354fa5baefaac392effaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/445 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\37529\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1110' max='1110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1110/1110 24:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.982022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.065232</td>\n",
       "      <td>0.986517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.063110</td>\n",
       "      <td>0.986517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061242</td>\n",
       "      <td>0.986517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.061593</td>\n",
       "      <td>0.986517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.068858</td>\n",
       "      <td>0.986517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.061063</td>\n",
       "      <td>0.988764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>0.984270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.066623</td>\n",
       "      <td>0.984270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.066502</td>\n",
       "      <td>0.984270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.984\n",
      "\n",
      "Predictions: [('tech', 0.9899190664291382), ('sport', 0.9932069182395935)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classifier = BertNewsClassifier()\n",
    "    data_split = classifier.load_data()\n",
    "\n",
    "    # –æ–±—É—á–µ–Ω–∏–µ\n",
    "    classifier.train(data_split)\n",
    "\n",
    "    # —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑\n",
    "    sample_texts = [\n",
    "        \"Apple announced a breakthrough in quantum computing\",\n",
    "        \"Premier League transfers reached record spending this summer\"\n",
    "    ]\n",
    "    print(\"\\nPredictions:\", classifier.predict(sample_texts))\n",
    "\n",
    "    # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "    classifier.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d87a9816-9d67-45ad-9c74-317d247a112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º bbc_additional...\n",
      "   filename     true_label predicted_label  confidence\n",
      "0     1.txt       business        business    0.999998\n",
      "1     2.txt       business        business    0.999998\n",
      "2     3.txt       business        business    0.999998\n",
      "3     4.txt       business        business    0.999999\n",
      "4     5.txt       business        politics    0.999985\n",
      "5     1.txt  entertainment   entertainment    0.999998\n",
      "6     2.txt  entertainment   entertainment    0.999998\n",
      "7     3.txt  entertainment   entertainment    0.999998\n",
      "8     4.txt  entertainment   entertainment    0.999998\n",
      "9     5.txt  entertainment   entertainment    0.999998\n",
      "10    1.txt       politics        politics    0.999999\n",
      "11    2.txt       politics        politics    0.999999\n",
      "12    3.txt       politics        politics    0.999998\n",
      "13    4.txt       politics        politics    0.999999\n",
      "14    5.txt       politics        politics    0.999999\n",
      "15    1.txt          sport           sport    0.999999\n",
      "16    2.txt          sport           sport    0.999998\n",
      "17    3.txt          sport           sport    0.999998\n",
      "18    4.txt          sport           sport    0.999998\n",
      "19    5.txt          sport           sport    0.999999\n",
      "20    1.txt           tech            tech    0.999998\n",
      "21    2.txt           tech            tech    0.999979\n",
      "22    3.txt           tech        business    0.979362\n",
      "23    4.txt           tech        business    0.999998\n",
      "24    5.txt           tech            tech    0.999998\n",
      "\n",
      "Accuracy on additional dataset: 0.880\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'bbc_additional_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "MODEL_PATH = \"bert_model\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH).to(device)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "\n",
    "def load_additional_data(data_path='bbc_additional'):\n",
    "    classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "    texts, labels, filenames = [], [], []\n",
    "\n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(data_path, cls)\n",
    "        for file in os.listdir(class_dir):\n",
    "            with open(os.path.join(class_dir, file), 'r', encoding='latin-1') as f:\n",
    "                texts.append(f.read())\n",
    "                labels.append(cls)\n",
    "                filenames.append(file)\n",
    "\n",
    "    return pd.DataFrame({'filename': filenames, 'text': texts, 'true_label': labels})\n",
    "\n",
    "\n",
    "def predict(texts):\n",
    "    inputs = tokenizer(\n",
    "        list(texts),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    preds = probs.argmax(dim=1)\n",
    "    id2label = {0: 'business', 1: 'entertainment', 2: 'politics', 3: 'sport', 4: 'tech'}\n",
    "    return [(id2label[p.item()], probs[i][p].item()) for i, p in enumerate(preds)]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º bbc_additional...\")\n",
    "    df_additional = load_additional_data()\n",
    "    \n",
    "    df_additional['predicted_label'], df_additional['confidence'] = zip(*predict(df_additional['text']))\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(df_additional['true_label'], df_additional['predicted_label'])\n",
    "    \n",
    "    \n",
    "    print(df_additional[['filename', 'true_label', 'predicted_label', 'confidence']])\n",
    "    print(f\"\\n—Ç–æ—á–Ω–æ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {accuracy:.3f}\")\n",
    "    \n",
    "    \n",
    "    df_additional.to_csv('bbc_additional_predictions.csv', index=False)\n",
    "    print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'bbc_additional_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a2795e0-d587-4a00-9d63-452c2ffb8cd1",
   "metadata": {},
   "source": [
    "bbc/business/1.txt\thttps://www.bbc.com/news/articles/cx20yw9e8yqo\n",
    "bbc/business/2.txt\thttps://www.bbc.com/news/articles/ckgzjn7m0vvo\n",
    "bbc/business/3.txt\thttps://www.bbc.com/news/articles/c3e4d8epdzdo\n",
    "bbc/business/4.txt\thttps://www.bbc.com/news/articles/cm2y8222ye4o\n",
    "bbc/business/5.txt\thttps://www.bbc.com/news/articles/cx2r3md0j84o\n",
    "\n",
    "bbs/entertainment/1.txt\thttps://www.bbc.com/news/articles/c4gp6ljnq23o\n",
    "bbs/entertainment/2.txt\thttps://www.bbc.com/news/articles/c0mwp3yp972o\n",
    "bbs/entertainment/3.txt\thttps://www.bbc.com/news/articles/c6253d37ylvo\n",
    "bbs/entertainment/4.txt\thttps://www.bbc.com/news/articles/cly41ww6e2do\n",
    "bbs/entertainment/5.txt\thttps://www.bbc.com/news/videos/cg4kvg02w7ko\n",
    "\n",
    "bbs/politics/1.txt\thttps://www.bbc.com/news/articles/c70w17dj258o\n",
    "bbs/politics/2.txt\thttps://www.bbc.com/news/articles/cvg5j74ld9lo\n",
    "bbs/politics/3.txt\thttps://www.bbc.com/news/articles/c4g0pp3mz1wo\n",
    "bbs/politics/4.txt\thttps://www.bbc.com/news/articles/cm2y82rk4kpo\n",
    "bbs/politics/5.txt\thttps://www.bbc.com/news/articles/cly6gz9j3rno\n",
    "\n",
    "\n",
    "bbs/sport/1.txt\thttps://www.bbc.com/sport/cricket/articles/cvgpjr7v5zmo\n",
    "bbs/sport/2.txt\thttps://www.bbc.com/sport/football/articles/cgm14y04g04o\n",
    "bbs/sport/3.txt\thttps://www.bbc.com/sport/horse-racing/articles/c4gdr979k5po\n",
    "bbs/sport/4.txt\thttps://www.bbc.com/sport/formula1/articles/ce8mr3rvyd5o\n",
    "bbs/sport/5.txt\thttps://www.bbc.com/sport/rugby-union/articles/cge1z2y0pg2o\n",
    "\n",
    "bbs/tech/1.txt\thttps://www.bbc.com/news/articles/c5yrjkl7dd6o\n",
    "bbs/tech/2.txt\thttps://www.bbc.com/news/articles/cz61yxv6evjo\n",
    "bbs/tech/3.txt\thttps://www.bbc.com/news/articles/ckgnvyggye1o\n",
    "bbs/tech/4.txt\thttps://www.bbc.com/news/articles/cdjy8x9w9zzo\n",
    "bbs/tech/5.txt\thttps://www.bbc.com/news/articles/czdnv6le71eo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
